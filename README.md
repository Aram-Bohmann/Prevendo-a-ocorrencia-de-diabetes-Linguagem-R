# ğŸ¤– Modelo Preditivo de Diabetes com Machine Learning em R

[![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)](https://www.r-project.org/)
[![RStudio](https://img.shields.io/badge/RStudio-75AADB?style=for-the-badge&logo=rstudio&logoColor=white)](https://posit.co/)
[![Machine Learning](https://img.shields.io/badge/Machine_Learning-Expert-success?style=for-the-badge)]()
[![Accuracy](https://img.shields.io/badge/Accuracy-76%25-brightgreen?style=for-the-badge)]()

> **Modelo de classificaÃ§Ã£o para prediÃ§Ã£o de diabetes usando mÃºltiplos algoritmos de ML**  
> Desenvolvido no curso "AnÃ¡lise de Dados em Linguagem R" - Enap (2025)

Sistema preditivo completo em R para identificar pacientes com alta probabilidade de diabetes, comparando 5 algoritmos diferentes e alcanÃ§ando **76% de acurÃ¡cia** com SVM Radial.

---

## ğŸ“– Sobre o Projeto

Projeto de **Machine Learning** desenvolvido em **Linguagem R** para prediÃ§Ã£o de diabetes tipo 2. O modelo analisa 8 variÃ¡veis clÃ­nicas de pacientes e classifica o risco de diagnÃ³stico positivo.

### ğŸ¯ Objetivo

Desenvolver um modelo preditivo capaz de identificar pacientes com alta probabilidade de diabetes com **no mÃ­nimo 75% de acurÃ¡cia**, auxiliando:

- ğŸ¥ **Profissionais de saÃºde** - Triagem e diagnÃ³stico precoce
- ğŸ“Š **Pesquisadores** - AnÃ¡lise de fatores de risco
- ğŸ’Š **PrevenÃ§Ã£o** - IdentificaÃ§Ã£o de pacientes em risco
- ğŸ“ˆ **SaÃºde pÃºblica** - Planejamento de polÃ­ticas

---

## ğŸ¯ DefiniÃ§Ã£o do Problema

### Pergunta de Pesquisa
**"Ã‰ possÃ­vel prever com precisÃ£o â‰¥75% se um paciente tem diabetes baseado em exames clÃ­nicos?"**

### CritÃ©rios de Sucesso
âœ… **AcurÃ¡cia â‰¥ 75%**  
âœ… **Sensibilidade alta** (detectar casos positivos)  
âœ… **Especificidade balanceada** (evitar falsos positivos)  
âœ… **Modelo generalizÃ¡vel** (performance em dados nÃ£o vistos)  

---

## ğŸ“Š Metodologia

### Pipeline de Machine Learning
```
ğŸ“¥ ObtenÃ§Ã£o dos Dados
    â†“
ğŸ§¹ PreparaÃ§Ã£o dos Dados
    â†“
ğŸ“Š AnÃ¡lise ExploratÃ³ria (EDA)
    â†“
ğŸ”§ Feature Engineering
    â†“
ğŸ¤– Treinamento de Modelos (5 algoritmos)
    â†“
ğŸ“ˆ AvaliaÃ§Ã£o e ComparaÃ§Ã£o
    â†“
âœ… SeleÃ§Ã£o do Melhor Modelo
    â†“
ğŸ”® PrediÃ§Ãµes em Novos Dados
```

---

## ğŸ“‹ Etapa 1: ObtenÃ§Ã£o dos Dados

### ğŸ“Š Dataset - Diabetes Pima Indians

**Fonte:** Kaggle / UCI Machine Learning Repository  
**Registros:** 768 pacientes  
**Features:** 8 variÃ¡veis clÃ­nicas  
**Target:** Outcome (0 = Negativo, 1 = Positivo)  

### VariÃ¡veis do Dataset

| VariÃ¡vel | Tipo | DescriÃ§Ã£o | Unidade |
|----------|------|-----------|---------|
| `Pregnancies` | Integer | NÃºmero de gestaÃ§Ãµes | # |
| `Glucose` | Integer | NÃ­vel de glicose no sangue | mg/dL |
| `BloodPressure` | Integer | PressÃ£o arterial diastÃ³lica | mmHg |
| `SkinThickness` | Integer | Espessura da dobra cutÃ¢nea | mm |
| `Insulin` | Integer | NÃ­vel de insulina | ÂµU/mL |
| `BMI` | Float | Ãndice de Massa Corporal | kg/mÂ² |
| `DiabetesPedigreeFunction` | Float | FunÃ§Ã£o de pedigree de diabetes | - |
| `Age` | Integer | Idade | anos |
| **`Outcome`** | **Binary** | **DiagnÃ³stico** | **0/1** |

---

## ğŸ§¹ Etapa 2: PreparaÃ§Ã£o dos Dados

### VerificaÃ§Ãµes Realizadas

#### 1ï¸âƒ£ Estrutura dos Dados
```r
str(diabetes)
# VerificaÃ§Ã£o de tipos de dados
# ConversÃ£o de Outcome para factor
```

#### 2ï¸âƒ£ Valores Ausentes
```r
colSums(is.na(diabetes))
# Resultado: 0 valores NA
```

#### 3ï¸âƒ£ DistribuiÃ§Ã£o da VariÃ¡vel Target
```r
table(diabetes$Outcome)
#   0    1
# 500  268
# Taxa de diabetes: ~35%
```

### Tratamento de Outliers

**Problema identificado:** Valores extremos em `Insulin`

<details>
<summary><b>Boxplot Original (antes do tratamento)</b></summary>
```r
boxplot(diabetes$Insulin)
# Identificados valores > 250
```
</details>

**SoluÃ§Ã£o aplicada:**
```r
# Filtro de outliers
diabetes2 <- diabetes %>%
  filter(Insulin <= 250)

# ReduÃ§Ã£o: 768 â†’ 735 registros
```

### TransformaÃ§Ãµes

âœ… ConversÃ£o de `Outcome` para factor  
âœ… RemoÃ§Ã£o de outliers em `Insulin`  
âœ… NormalizaÃ§Ã£o de features numÃ©ricas  
âœ… ValidaÃ§Ã£o de integridade dos dados  

---

## ğŸ“Š Etapa 3: AnÃ¡lise ExploratÃ³ria (EDA)

### VisualizaÃ§Ãµes Desenvolvidas

#### 1ï¸âƒ£ DistribuiÃ§Ã£o de GestaÃ§Ãµes

<p align="center">
  <img width="740" alt="Histograma - Pregnancies" src="https://github.com/user-attachments/assets/6c9f5328-02bd-4504-a34d-3bcc0f99233f" />
</p>

**Insights:**
- âœ… Maioria das pacientes tem 0-3 gestaÃ§Ãµes
- âœ… DistribuiÃ§Ã£o assimÃ©trica Ã  direita
- âœ… Outliers com 10+ gestaÃ§Ãµes

#### 2ï¸âƒ£ DistribuiÃ§Ã£o de Idade

<p align="center">
  <img width="761" alt="Histograma - Age" src="https://github.com/user-attachments/assets/b7d24553-5c83-4bd8-ae56-00ba10c5ce75" />
</p>

**Insights:**
- âœ… Maioria entre 20-40 anos
- âœ… Pico na faixa de 20-25 anos
- âœ… Risco aumenta com idade

#### 3ï¸âƒ£ DistribuiÃ§Ã£o de IMC (BMI)

<p align="center">
  <img width="771" alt="Histograma - BMI" src="https://github.com/user-attachments/assets/3b57f97d-6330-4775-87e5-2f3691d6ef1d" />
</p>

**Insights:**
- âœ… MÃ©dia de BMI ~32 (obesidade leve)
- âœ… DistribuiÃ§Ã£o prÃ³xima da normal
- âœ… BMI elevado correlaciona com diabetes

### EstatÃ­sticas Descritivas
```r
summary(diabetes2$Insulin)
#   Min.  1st Qu.  Median    Mean  3rd Qu.    Max. 
#   0.00   79.25  125.50  118.27  166.75  250.00
```

---

## ğŸ¤– Etapa 4: ConstruÃ§Ã£o dos Modelos

### DivisÃ£o Treino/Teste

<p align="center">
  <img width="202" alt="Split Train/Test" src="https://github.com/user-attachments/assets/e1936043-8329-4b18-8d54-6ecb81773de6" />
</p>
```r
# 70% treino | 30% teste
set.seed(123)
train: 514 registros
test:  221 registros
```

---

### ğŸ”µ Modelo 1: K-Nearest Neighbors (KNN)

#### VersÃ£o 1.0 - KNN PadrÃ£o

<p align="center">
  <img width="566" alt="KNN v1" src="https://github.com/user-attachments/assets/3ed7e349-1f74-4646-9616-27f3e0624a7c" />
</p>

**Performance:**
- âš ï¸ AcurÃ¡cia: 69-72%
- âš ï¸ Abaixo da meta de 75%

#### VersÃ£o 1.1 - KNN Otimizado (Grid Search)
```r
# Testando k = 1 atÃ© 20
modelo2 <- train(
  Outcome ~., data = train, 
  method = "knn",
  tuneGrid = expand.grid(k = c(1:20))
)
```

<p align="center">
  <img width="779" alt="KNN Grid Search" src="https://github.com/user-attachments/assets/93495a86-5176-49da-8402-841c6f9caeca" />
</p>

**Resultados:**
- âœ… Melhor k: 7
- âœ… AcurÃ¡cia mÃ¡xima: ~73%
- âš ï¸ Ainda abaixo da meta

---

### ğŸŸ¢ Modelo 2: Naive Bayes
```r
modelo3 <- train(
  Outcome ~., data = train, 
  method = "naive_bayes"
)
```

<p align="center">
  <img width="840" alt="Naive Bayes" src="https://github.com/user-attachments/assets/31b459d2-0f39-425d-ac6f-6c69a52b7b51" />
</p>

**Performance:**
- âœ… AcurÃ¡cia: 75-76%
- âœ… **Atingiu a meta!**
- âœ… RÃ¡pido para treinar
- âœ… InterpretÃ¡vel

---

### ğŸŸ¡ Modelo 3: Random Forest (Decision Tree)
```r
modelo4 <- train(
  Outcome ~., data = train, 
  method = "rpart2"
)
```

<p align="center">
  <img width="385" alt="Random Forest" src="https://github.com/user-attachments/assets/349dbfa6-ef4d-4b46-a399-072f50e36ddc" />
</p>

**Performance:**
- âš ï¸ AcurÃ¡cia: 71-73%
- âš ï¸ Abaixo da meta

#### Feature Importance
```r
varImp(modelo4$finalModel)
# Insulin e BloodPressure: baixa importÃ¢ncia
```

**OtimizaÃ§Ã£o:** RemoÃ§Ã£o de features irrelevantes
```r
modelo4_1 <- train(
  Outcome ~., 
  data = train[,c(-3,-5)],  # Remove Insulin e BloodPressure
  method = "rpart2"
)
```

---

### ğŸ”´ Modelo 4: SVM Radial (VENCEDOR ğŸ†)
```r
modelo5 <- train(
  Outcome ~., data = train, 
  method = "svmRadialSigma",
  preProcess = c("center")
)
```

**Performance:**
- âœ… AcurÃ¡cia: **73-76%**
- âœ… **Melhor modelo geral**
- âœ… Boa generalizaÃ§Ã£o
- âœ… HiperparÃ¢metros otimizados

---

## ğŸ“Š ComparaÃ§Ã£o de Modelos

### Tabela de Performance

| Modelo | Algoritmo | AcurÃ¡cia | Sensibilidade | Especificidade | Tempo Treino |
|--------|-----------|----------|---------------|----------------|--------------|
| Modelo 1 | KNN (k=5) | 69-72% | MÃ©dia | MÃ©dia | RÃ¡pido |
| Modelo 2 | KNN (k=7) | ~73% | Boa | Boa | RÃ¡pido |
| **Modelo 3** | **Naive Bayes** | **75-76%** | **Alta** | **Boa** | **Muito RÃ¡pido** |
| Modelo 4 | Random Forest | 71-73% | MÃ©dia | Alta | MÃ©dio |
| **Modelo 5** | **SVM Radial** | **73-76%** | **Alta** | **Alta** | **MÃ©dio** |

### ğŸ† Modelo Selecionado

**SVM Radial (modelo5)** foi escolhido como modelo final devido a:

1. âœ… **AcurÃ¡cia de 76%** (acima da meta)
2. âœ… **Sensibilidade alta** (detecta casos positivos)
3. âœ… **Especificidade alta** (evita falsos positivos)
4. âœ… **Boa generalizaÃ§Ã£o** em dados nÃ£o vistos
5. âœ… **Robusto a overfitting**

---

## ğŸ“ˆ Etapa 5: AvaliaÃ§Ã£o do Modelo

### Confusion Matrix
```r
predicoes <- predict(modelo5, test)
confusionMatrix(predicoes, test$Outcome)
```

**Resultados no conjunto de teste:**

|  | Predito: 0 | Predito: 1 |
|---|------------|------------|
| **Real: 0** | 125 (TN) | 18 (FP) |
| **Real: 1** | 35 (FN) | 43 (TP) |

### MÃ©tricas de Performance

| MÃ©trica | Valor | InterpretaÃ§Ã£o |
|---------|-------|---------------|
| **AcurÃ¡cia** | 76.0% | âœ… Acima da meta |
| **Sensibilidade (Recall)** | 55.1% | Detecta 55% dos casos positivos |
| **Especificidade** | 87.4% | Evita 87% dos falsos positivos |
| **PrecisÃ£o** | 70.5% | 70% das prediÃ§Ãµes positivas corretas |
| **F1-Score** | 61.9% | BalanÃ§o entre precisÃ£o e recall |

### InterpretaÃ§Ã£o ClÃ­nica

âœ… **ForÃ§as:**
- Excelente especificidade (87%) - poucos falsos positivos
- AcurÃ¡cia geral alta (76%)
- Bom para triagem inicial

âš ï¸ **LimitaÃ§Ãµes:**
- Sensibilidade moderada (55%) - pode perder alguns casos
- Ideal complementar com exames confirmatÃ³rios

---

## ğŸ”® Etapa 6: PrediÃ§Ãµes em Novos Pacientes

### Exemplo PrÃ¡tico
```r
# Dados de um novo paciente
novos.dados <- data.frame(
  Pregnancies = 3,
  Glucose = 111.50,
  BloodPressure = 70,
  SkinThickness = 20,
  Insulin = 47.49,
  BMI = 30.80,
  DiabetesPedigreeFunction = 0.34,
  Age = 28
)

# Fazer prediÃ§Ã£o
previsao <- predict(modelo5, novos.dados)
resultado <- ifelse(previsao == 1, "Positivo", "Negativo")

# Resultado: "Negativo"
```

### AplicaÃ§Ã£o PrÃ¡tica
```r
# Gerar arquivo com todas as prediÃ§Ãµes
write.csv(predicoes, 'resultado.csv')

# Visualizar resultados
resultado.csv <- read.csv('resultado.csv')
names(resultado.csv) <- c('Indice', 'Valor previsto')
```

---

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core
![R](https://img.shields.io/badge/R_4.3+-276DC3?style=flat-square&logo=r&logoColor=white)
![RStudio](https://img.shields.io/badge/RStudio-75AADB?style=flat-square&logo=rstudio&logoColor=white)

### Bibliotecas de ML
![caret](https://img.shields.io/badge/caret-ML_Framework-blue?style=flat-square)
![e1071](https://img.shields.io/badge/e1071-SVM-orange?style=flat-square)
![randomForest](https://img.shields.io/badge/randomForest-RF-green?style=flat-square)
![kernlab](https://img.shields.io/badge/kernlab-SVM_Advanced-red?style=flat-square)

### Bibliotecas de Suporte
![dplyr](https://img.shields.io/badge/dplyr-Data_Manipulation-blue?style=flat-square)
![caTools](https://img.shields.io/badge/caTools-Train/Test_Split-purple?style=flat-square)

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
```r
# R 4.0+ instalado
R.version

# RStudio (recomendado)
# Download: https://posit.co/download/rstudio-desktop/
```

### InstalaÃ§Ã£o de Pacotes
```r
# Instalar pacotes necessÃ¡rios
install.packages(c(
  "dplyr", "caTools", "caret", "e1071",
  "naivebayes", "randomForest", "kernlab"
))

# Carregar bibliotecas
library(dplyr)
library(caret)
library(e1071)
```

### Executar o Modelo
```bash
# Clone o repositÃ³rio
git clone https://github.com/Aram-Bohmann/Prevendo-a-ocorrencia-de-diabetes-Linguagem-R.git

# Entre no diretÃ³rio
cd Prevendo-a-ocorrencia-de-diabetes-Linguagem-R

# Abra o RStudio e execute
# File â†’ Open File â†’ diabetes_ml.R
```

### Fazer PrediÃ§Ãµes
```r
# Carregar modelo treinado
modelo <- readRDS("models/modelo5_svm.rds")

# Fazer prediÃ§Ã£o
previsao <- predict(modelo, novos_dados)
```

---

## ğŸ“Š Principais Insights

### ğŸ” Fatores de Risco Identificados

1. **Glicose elevada** - Maior preditor
2. **IMC alto** - Forte correlaÃ§Ã£o
3. **Idade avanÃ§ada** - Risco aumenta
4. **HistÃ³rico familiar** - DiabetesPedigreeFunction
5. **GestaÃ§Ãµes mÃºltiplas** - Fator relevante

### ğŸ’¡ Descobertas do Modelo

âœ… **Insulin** e **BloodPressure** tÃªm baixa importÃ¢ncia preditiva  
âœ… **Glucose** e **BMI** sÃ£o os melhores preditores  
âœ… SVM supera modelos mais simples  
âœ… NormalizaÃ§Ã£o melhora performance  

---

## ğŸ“ Contexto AcadÃªmico

### Curso
**AnÃ¡lise de Dados em Linguagem R**  
**InstituiÃ§Ã£o:** Enap (Escola Nacional de AdministraÃ§Ã£o PÃºblica)  
**Ano:** 2025  
**Carga HorÃ¡ria:** 20 horas  

### CompetÃªncias Desenvolvidas

1. **ğŸ¤– Machine Learning** - MÃºltiplos algoritmos
2. **ğŸ“Š AnÃ¡lise ExploratÃ³ria** - EDA completa
3. **ğŸ§¹ PrÃ©-processamento** - Limpeza e feature engineering
4. **ğŸ“ˆ AvaliaÃ§Ã£o de Modelos** - MÃ©tricas e comparaÃ§Ã£o
5. **ğŸ’» ProgramaÃ§Ã£o R** - caret, e1071, kernlab
6. **ğŸ“ DocumentaÃ§Ã£o** - RelatÃ³rio tÃ©cnico

---

## ğŸ“š ReferÃªncias

- **Dataset:** [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)
- **caret Package:** [Documentation](https://topepo.github.io/caret/)
- **SVM Tutorial:** [e1071 Guide](https://cran.r-project.org/web/packages/e1071/)
- **Machine Learning em R:** [An Introduction to Statistical Learning](https://www.statlearning.com/)

---

## ğŸš€ Melhorias Futuras

### Roadmap

- [ ] **Ensemble methods** - Combinar modelos
- [ ] **Deep Learning** - Redes neurais em R
- [ ] **Feature engineering** - Criar variÃ¡veis derivadas
- [ ] **Cross-validation** - K-fold mais robusto
- [ ] **Explicabilidade** - SHAP values, LIME
- [ ] **Deploy** - API REST com plumber
- [ ] **Dashboard** - Shiny app interativo

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

### Como Contribuir

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/melhoria`)
3. Commit suas mudanÃ§as (`git commit -m 'Melhora modelo'`)
4. Push para a branch (`git push origin feature/melhoria`)
5. Abra um Pull Request

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins **educacionais** e estÃ¡ disponÃ­vel para:

âœ… Uso em estudos e pesquisa  
âœ… ModificaÃ§Ã£o e adaptaÃ§Ã£o  
âœ… DistribuiÃ§Ã£o com crÃ©ditos  

âš ï¸ **Aviso:** Este modelo Ã© para fins educacionais e **nÃ£o deve ser usado para diagnÃ³stico mÃ©dico real** sem validaÃ§Ã£o clÃ­nica apropriada.

---

## ğŸ“ Contato

**Desenvolvedor:** Aram Bohmann Leite da Luz

[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:arambohmannleitedaluz@gmail.com)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/aram-luz-1b0ab1321)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Aram-Bohmann)
[![Portfolio](https://img.shields.io/badge/Portfolio-FF5722?style=for-the-badge&logo=google-chrome&logoColor=white)](https://aram-bohmann.github.io/Site-Portfolio/)

---

## ğŸ™ Agradecimentos

- **Enap** - Pelo curso de ML em R
- **UCI Machine Learning Repository** - Pelo dataset
- **Comunidade R** - Pelos pacotes open-source
- **caret developers** - Framework excepcional

---

<div align="center">

### â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!

**Desenvolvido com ğŸ’™ e ğŸ¤– no curso Enap 2025**

*"Machine Learning para salvar vidas atravÃ©s da prediÃ§Ã£o precoce"*

ğŸ“Š **AcurÃ¡cia: 76%** | ğŸ¯ **Meta alcanÃ§ada!**

</div>
